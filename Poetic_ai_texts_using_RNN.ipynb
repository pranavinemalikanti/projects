{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavinemalikanti/projects/blob/main/Poetic_ai_texts_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726f088b",
      "metadata": {
        "id": "726f088b",
        "outputId": "03d66bbd-a0f2-4a7b-df99-56d632f51391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imported\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "print(\"imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55bdfb2",
      "metadata": {
        "id": "b55bdfb2",
        "outputId": "885a652a-99a0-4da0-ce32-e120e20e41fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample\n"
          ]
        }
      ],
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "print(\"Sample\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b065c8c4",
      "metadata": {
        "id": "b065c8c4"
      },
      "outputs": [],
      "source": [
        "text = open(filepath,'rb').read().decode(encoding='utf-8').lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819634fb",
      "metadata": {
        "id": "819634fb"
      },
      "outputs": [],
      "source": [
        "text = text[300000:800000]  #sample data\n",
        "characters = sorted(set(text)) #making it a sorted set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec9bd74",
      "metadata": {
        "id": "eec9bd74"
      },
      "outputs": [],
      "source": [
        "#assigning index to char and vice-versa\n",
        "char_to_index = dict((c,i) for i,c in enumerate(characters))\n",
        "index_to_char = dict((i,c) for i,c in enumerate(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2bbcc99",
      "metadata": {
        "id": "b2bbcc99"
      },
      "outputs": [],
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81076ab",
      "metadata": {
        "id": "a81076ab"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "next_char = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828f243e",
      "metadata": {
        "id": "828f243e"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i+SEQ_LENGTH])                #loading sentences\n",
        "    next_char.append(text[i+SEQ_LENGTH])                   #loading sentence's next character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f15b81",
      "metadata": {
        "id": "e6f15b81"
      },
      "outputs": [],
      "source": [
        "#convert sentences to numerical format - input 3d array\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
        "#convert next char to numerical format - output 2d array\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df53003",
      "metadata": {
        "id": "2df53003"
      },
      "outputs": [],
      "source": [
        "#enter 1 or 0 for inputs and output\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, character in enumerate(sentence):\n",
        "        x[i, t, char_to_index[character]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebac0e62",
      "metadata": {
        "id": "ebac0e62"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('C:/Users/pranavi/Desktop/TFProj/TFProjtextGen.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4699d4",
      "metadata": {
        "id": "ba4699d4"
      },
      "outputs": [],
      "source": [
        "#predictions\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc5cdcc",
      "metadata": {
        "id": "2dc5cdcc"
      },
      "outputs": [],
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, character in enumerate(sentence):\n",
        "            x[0, t, char_to_index[character]] = 1\n",
        "\n",
        "        predictions = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(predictions, temperature)\n",
        "        next_char = index_to_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e8244ce",
      "metadata": {
        "scrolled": true,
        "id": "6e8244ce",
        "outputId": "0cf04015-7d18-435a-fafa-f2b666408ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ch salt water thrown away in waste,\n",
            "to stand as thou brother and the singer hath been\n",
            "the canst the sorrow the part and the sunder\n",
            "the since the forture of the soul the sorrow.\n",
            "\n",
            "king richard ii:\n",
            "what see the sing in the bear the soul,\n",
            "that i see the surden be some service their since.\n",
            "\n",
            "king richard ii:\n",
            "well shall be the sing the and the s\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(300,0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03154b56",
      "metadata": {
        "id": "03154b56",
        "outputId": "654c75b7-8af4-4026-bbf4-4358df5950a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "afford\n",
            "no better term than this,--thou art a man,\n",
            "and thou art thou brow the world and bear thee:\n",
            "that sweat the prooped her charge and should\n",
            "been him is the strease her forture with me.\n",
            "\n",
            "bullond:\n",
            "heaven for in the death thou that i can too present\n",
            "the sirs me seat the fair him the sirment.\n",
            "\n",
            "henry bolingbroke:\n",
            "i will be with the sir, and\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(300,0.4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf689adf",
      "metadata": {
        "id": "bf689adf",
        "outputId": "7ef06878-1a93-4399-ad79-eb2c645bd3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thou speak'st speak not of remedy.\n",
            "\n",
            "frianchence:\n",
            "i am good notling brow noull shool i\n",
            "sursein the conso: by what the fiest.\n",
            "\n",
            "henry bolingbroke:\n",
            "heref it dis'ph\n",
            "the parth are to stread these sir, he my\n",
            "new may he,\n",
            "adwar of that most thou somethmen would be.\n",
            "\n",
            "fordg marriov:\n",
            "you have a many it untook knine.\n",
            "\n",
            "king edward iv:\n",
            "o the bursunow.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(300,0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c68a342b",
      "metadata": {
        "id": "c68a342b",
        "outputId": "7cb6d276-c74b-4a32-990c-0cb1de322da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wain, awhile, beseech you;\n",
            "have you a faint more fear and spccp prince!\n",
            "-o master betwarding crospancties-nake,\n",
            "disin no cook:'\n",
            "too behild of warsing fight fathermoved and for.\n",
            "\n",
            "mercutio:\n",
            "comes followendle and him in the and.\n",
            "\n",
            "frear matis:\n",
            "and but make a serven as we both or him:\n",
            "make a heast caire and that goow, hear many's\n",
            "or surdet or \n"
          ]
        }
      ],
      "source": [
        "print(generate_text(300,1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da343780",
      "metadata": {
        "id": "da343780"
      },
      "outputs": [],
      "source": [
        "#Training neural network\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc38b481",
      "metadata": {
        "id": "fc38b481"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42edcca",
      "metadata": {
        "id": "e42edcca",
        "outputId": "1f62ca15-ef4a-431f-cd24-09894a3bcc6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 166ms/step - loss: 2.4867\n",
            "Epoch 2/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 162ms/step - loss: 1.7747\n",
            "Epoch 3/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 167ms/step - loss: 1.6072\n",
            "Epoch 4/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 163ms/step - loss: 1.5299\n"
          ]
        }
      ],
      "source": [
        "model.fit(x, y, batch_size=256, epochs=4)\n",
        "model.save('C:/Users/pranavi/Desktop/TFProj/TFProjtextGen.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bb3ccc",
      "metadata": {
        "id": "82bb3ccc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tfkernel",
      "language": "python",
      "name": "tfkernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}